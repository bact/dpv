{% from 'macro_term_table.jinja2' import table_classes %}
{% from 'macro_term_table.jinja2' import table_properties %}
{% from 'macro_term_table.jinja2' import list_hierarchy, index_concepts %}
{% from 'macro_dpv_document_family.jinja2' import dpv_document_family, sotd, funding_acknowledgements %}
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AI Technology Concepts</title>
  <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
  <script class="remove">
   // All config options at https://respec.org/docs/ 
   var respecConfig = {
    shortName: "ai",
    title: "{{data[vocab_name+'-metadata']['dct:title']}} ({{vocab_name|upper}})",
    subtitle: "version {{data[vocab_name+'-metadata']['schema:version']}}",
    publishDate: "2024-08-01",
    specStatus: "{{DOCUMENT_STATUS}}",
    group: "dpvcg",
    latestVersion: "https://w3id.org/dpv/ai",
    canonicalUri: "https://w3id.org/dpv/ai",
    edDraftURI: "https://dev.dpvcg.org/ai",
    github: "w3c/dpv",
    subjectPrefix: "[ai]",
    doJsonLd: true,
    lint: { "no-unused-dfns": false },
    editors: [
    {
      name: "Harshvardhan J. Pandit",
      url: "https://harshp.com",
      "company": "{{ "Harshvardhan J. Pandit" | generate_author_affiliation }}"
    }
    ],
    authors: [{% for person in data[vocab_name+'-metadata']['dct:creator']|ensure_list|sort %}
      {
        "name": "{{person}}",
        "company": "{{ person | generate_author_affiliation }}"
      }{{"," if not loop.last}}
      {% endfor %}],
    otherLinks: [
      {
        "key": "This Release",
        "data": [
            {
              "value": "https://w3id.org/dpv/2.0/ai",
              "href": "https://w3id.org/dpv/2.0/ai"
            }
        ]
      },
      {
        "key": "Key Publications",
        "data": [
            {
              "value": "Data Privacy Vocabulary (DPV) -- Version 2 (2024)",
              "href": "https://arxiv.org/abs/2404.13426"
            },
            {
              "value": "To Be High-Risk, or Not To Be—Semantic Specifications and Implications of the AI Act’s High-Risk AI Applications and Harmonised Standards (2023)",
              "href": "https://doi.org/10.1145/3593013.3594050"
            },
            {
              "value": "AIRO: an Ontology for Representing AI Risks based on the Proposed EU AI Act and ISO Risk Management Standards (2022)",
              "href": "https://doi.org/10.3233/SSW220008"
            }
        ]
      }
    ],
    localBiblio: {%  include 'references.json' %}
  };
</script>
<link rel="stylesheet" type="text/css" href="../diagrams/common.css">
<link rel="shortcut icon" href="../diagrams/favicon-16x16.png" type="image/x-icon" sizes="16x16" />
  <link rel="shortcut icon" href="../diagrams/favicon-32x32.png" type="image/x-icon" sizes="32x32" />
</head>
<body>
  <section id="abstract">
    <p>The AI extension extends the [[[DPV]]] and its [[[TECH]]] extension to represent AI techniques, applications, risks, and mitigations. The namespace for terms in <code>ai</code> is <a href="http://www.w3id.org/dpv/ai#"><code>https://www.w3id.org/dpv/ai#</code></a>. The suggested prefix for the namespace is <code>ai</code>. The AI vocabulary and its documentation are available on <a href="https://github.com/w3c/dpv">GitHub</a>.</p>
    <div class="issue" title="Change vocab status from DRAFT to FINAL"></div>
  </section>
    {{ sotd(data[vocab_name+'-metadata']) }}
    {{ dpv_document_family(document='ai-spec') }}

  <section id="vocab-core">
    <h2>Core Concepts</h2>
    <figure>
      <img src="../diagrams/ai.svg">
      <figcaption>Overview of AI extension</figcaption>
    </figure>
    <aside class="issue" title="Add new core concepts to Diagram for Data, Measure, Lifecycle, Risk, and tech:Function"></aside>
    <aside class="issue" title="Add new core concepts to list for Data, Measure, Lifecycle, Risk, and tech:Function"></aside>
    <p>The [[[AI]]] extension further extends the [[TECH]] extension to represent concepts specifically associated with development, use, and operation of AI, and provides:</p>
    <ul>
      <li><strong>Techniques</strong> such as machine learning and natural language programming</li>
      <li><strong>Capabilities</strong> such as image recognition and text generation</li>
      <li><strong>AI Systems and Models</strong> such as expert systems, or general purpose AI models (GPAI)</li>
      <li><strong>Data</strong> such as for training, testing, and validation</li>
      <li><strong>Risks</strong> such as data poisoning, statistical noise and bias, etc.</li>
      <li><strong>Risk Measures</strong> to address the AI specific risks</li>
      <li><strong>Lifecycle</strong> such as data collection, training, fine-tuning, etc.</li>
      <li><strong>Documentation</strong> such as Data Sheets and Model Cards</li>
      <li><strong>Actors</strong> such as AI Developer and AI Deployer</li>
      <li><strong>Status</strong> associated with AI development</li>
    </ul>
    <p>The AI extension is being created based on the following sources:</p>
    <ol>
      <li>[[[ISO-22989]]]</li>
      <li>[[[AIAct]]], which is also supported by the [[EU-AIAct]] extension for DPV</li>
      <li><a href="https://ai-watch.ec.europa.eu/publications/defining-artificial-intelligence-10_en">AI Watch taxonomy</a></li>
      <li><a href="https://w3id.org/airo">AI Risk Ontology (AIRO)</a> and <a href="https://w3id.org/vair">Vocabulary of AI Risks (VAIR)</a></li>
    </ol>

    <section>
      <h3>AI as a specific Technology</h3>
      <div class="issue" title="add content for section stating AI is just another technology, and we reuse DPV and TECH here"></div>
    </section>

    <section>
      <h3>Conceptual Model</h3>
      <div class="issue" title="add content section describing conceptual model: Technique to Capability to Purpose"></div>
    </section>
  </section>

  <section id="vocab-techniques">
    <h2>Techniques</h2>
    <aside class="issue" title="add content for Technique section - explain what is a Technique"></aside>
    {{ list_hierarchy(modules['techniques']['classes']) }}
  </section>

  <section id="vocab-capabilities">
    <h2>Capabilities</h2>
    <aside class="issue" title="add content for Capability section - explain what is a Capability"></aside>
    {{ list_hierarchy(modules['capabilities']['classes']) }}
  </section>

  <section id="vocab-systems">
    <h2>AI Systems and Models</h2>
    <aside class="issue" title="add content for AI System and Model section - explain what is a AI System and Model"></aside>
    <aside class="note" data-number="197"></aside>
    {{ list_hierarchy(modules['systems']['classes']) }}
  </section>

  <section id="vocab-data">
    <h2>Data</h2>
    <aside class="issue" title="add content for Data section"></aside>
    {{ list_hierarchy(modules['data']['classes']) }}
  </section>

  <section id="vocab-risks">
    <h2>Risk Concepts</h2>
    <div class="issue" title="Add a note and content describing risk concepts can take on different roles, and how to use them - see RISK docs for example"></div>
    <aside class="note" title="AI Risk concepts extend the RISK extension concepts">
      <p>The risk concepts presented in this extension are intended to represent concepts specific to AI development and use, and do not contain general risk concepts which exist in other contexts e.g. applicable for any (AI and non-AI) technology. The [[RISK]] extension contains the general set of concepts that this vocabulary extends to represent risks that are specific to the development and use of AI.</p>
    </aside>
    <p>The concept [=RiskConcept=] in this extension extends <code>dpv:RiskConcept</code> to represent risk sources, risks, concepts, and impacts specific to the development, use, or operation of AI. As with the [[RISK]] extension, the risk concepts presented here can taken on different roles in different use-cases, for example what is a risk source in one scenario could be the consequence in another. The relations <code>risk:hasRiskSource</code>, <code>dpv:hasRisk</code>, <code>dpv:hasConsequence</code>, and <code>dpv:hasImpact</code> are useful to indicate the specific interpretation and role of the AI risk concepts in a scenario.</p>
    <p>The AI Risk Concepts are broadly categorised according to the following:</p>
    <ol>
      <li>[=DataRisk=] - Risk associated with data used or produced or otherwise involved in the context of AI</li>
      <li>[=SecurityAttack=] - Risks or issues associated with security attacks related to AI technologies, models, and systems</li>
      <li>[=ModelRisk=] - Model Risk  Risks associated with AI Models</li>    
      <li>[=AISystemRisk=] - AI System Risk  Risks associated with AI Systems</li>    
      <li>[=UserRisk=] - User Risk Risks associated with Users of AI Systems</li>    
      <li>[=AIBias=] - AI Bias Bias associated with development, use, or other activities involving an AI technology or system</li>
    </ol>

    <section id="vocab-risks-data">
      <h3>Data Risks</h3>
      <aside class="note" title="Add content for Data Risks section"></aside>
      {{ list_hierarchy(modules['risks']['classes'], head='ai:DataRisk') }}
    </section>

    <section id="vocab-risks-bias">
      <h3>Bias</h3>
      <p>The bias concepts represented here are specific to AI, and there are generic bias concepts as well as discrimination impact concepts in [[RISK]] extension. While we are interested in further expanding these concepts, the following external sources should be of interest:</p>
      <ul>
        <li><a href="https://github.com/tibonto/Doc-BIAS">DocBiasO</a> - an ontology-driven approach to support the documentation of bias in data, which has a larger expansive categorisation of bias and provides additional concepts and properties to model specifics such as ethnicities and measurements which are useful in bias measurement and documentation.</li>
        <li><a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf">NIST Special Publication 1270 - Towards a Standard for Identifying and Managing Bias in Artificial Intelligence</a></li>
        <li><a href="https://www.iso.org/standard/77607.html">ISO/IEC TR 24027:2021 Information technology — Artificial intelligence (AI) — Bias in AI systems and AI aided decision making</li>
        <li><a href="https://oecd.ai/en/catalogue/tools?terms=bias&page=1">OECD AI Policy Observatory -  Catalogue of Tools & Metrics for Trustworthy AI</a></li>
      </ul>
      {{ list_hierarchy(modules['risks']['classes'], head='ai:AIBias') }}
    </section>

    <section id="vocab-risks-security-attack">
      <h3>Security Attacks</h3>
      <aside class="note" title="Add content for Security Attrack section"></aside>
      {{ list_hierarchy(modules['risks']['classes'], head='ai:SecurityAttack') }}
    </section>

    <aside class="issue" title="Add overview table for roles each risk concept can take - see RISK docs for example (reuse code from there)"></aside>

  <section id="vocab-measures">
    <h2>Risk Measures</h2>
    <aside class="note" title="Add content for Risk Measures concept - mention ai:Measure as parent concept and that we are looking to expand this in the future based on DPV TOMs taxonomies specifically for AI"></aside>
  </section>

</section>

<section id="vocab-lifecycle">
    <h2>Lifecycle</h2>
    <aside class="issue" title="Add content for Lifecycle section"></aside>
    <aside class="note" title="Alignment with lifecycle of technology">
      <p>We are currently exploring the alignment of these concepts, which are based on ISO/IEC 22989:2022, with those for lifecycle of technology (in general) as defined in  ISO/IEC/IEEE 15288:2023 Systems and software engineering — System life cycle processes. We have proposed inclusion of technology lifecycle concepts in the [[TECH]] extension, which would then be extended here in the AI extension.</p>
    </aside>
    {{ list_hierarchy(modules['lifecycle']['classes']) }}
  </section>
  

  <section id="vocabulary">
<h2>Vocabulary Index</h2>
  <section id="dpv-classes">
    {{ index_concepts(vocab, vocab_name, filter="classes") }}
  </section>
  <section id="dpv-properties">
    {{ index_concepts(vocab, vocab_name, filter="properties") }}
  </section>
  <section id="external-concepts">
    <p>DPV uses the following terms from [[RDF]] and  [[RDFS]] with their defined meanings:</p>
    <ul>
      <li id="rdf:type"><dfn>rdf:type</dfn> to denote a concept is an instance of another concept</li>
      <li id="rdfs:Class"><dfn>rdfs:Class</dfn> to denote a concept is a Class or a category</li>
      <li id="rdfs:subClassOf"><dfn>rdfs:subClassOf</dfn> to specify the concept is a subclass (subtype, sub-category, subset) of another concept</li>
      <li id="rdf:Property"><dfn>rdf:Property</dfn> to denote a concept is a property or a relation</li>
      </ul>
    <p>The following external concepts are re-used within DPV:</p>
    {{ index_concepts(vocab, vocab_name, filter="external") }}
  </section>
</section>
  
{% if proposed %}
<section id="proposed-terms" class="appendix">
  <h2>Proposed Terms</h2>
  <p>The following terms have been proposed for inclusion, and are under discussion. They are provided here for illustrative purposes and should not be considered as part of DPV.</p>
    <ul>{% for term in proposed %}
      <li>{{term}}</li>
    {% endfor %}</ul>
</section>
{% endif %}

{% block ACKNOWLEDGEMENTS %}
<section id="contributors">
  <h2>Contributors</h2>
  <p>The following people have contributed to this vocabulary. The names are ordered alphabetically. The affiliations are informative do not represent formal endorsements. Affiliations may be outdated. The list is generated automatically from the contributors listed for defined concepts.</p>
  <ul>
  {% for person in data[vocab_name+'-metadata']['dct:contributor']|ensure_list|sort %}
    <li>{{ person }} ({{person|generate_author_affiliation}})</li>
  {% endfor %}
  </ul>
</section>
<section id="funding-acknowledgements" class="notoc">
  <h2>Funding Acknowledgements</h2>

  <h3>Funding Sponsors</h3>
  {{ funding_acknowledgements() }}

  <h3>Funding Acknowledgements for Contributors</h3>
  <p>The contributions of Delaram Golpayegani have received funding through the <a href="https://protect-network.eu/">PROTECT ITN Project</a> from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 813497, in particular through the development of <a href="https://w3id.org/airo">AI Risk Ontology (AIRO)</a> and <a href="https://w3id.org/vair">Vocabulary of AI Risks (VAIR)</a> which have been integrated in to this extension.</p>
  <p>The contributions of Harshvardhan J. Pandit and Delaram Golpayegani have been made with the financial support of Science Foundation Ireland under Grant Agreement No. 13/RC/2106_P2 at the ADAPT SFI Research Centre.</p>

</section>
{% endblock ACKNOWLEDGEMENTS %}
<section class="appendix" id="issue-summary"></section>
<script type="text/javascript" src="../diagrams/common.js" defer></script>
</body>
</html>